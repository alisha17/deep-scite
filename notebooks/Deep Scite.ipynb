{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Experimenting with Deep Scite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Recall the model, for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](deep-scite-model-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from deepscite import model\n",
    "from deepscite import utils\n",
    "from deepscite import train\n",
    "import ruamel.yaml\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_dir = \"../\"\n",
    "data_dir = os.path.join(base_dir, \"data/noon_less_words/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's define the parameters we want to use during training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Update the `conf` global state that we use in various places in the model.\n",
    "conf = tf.app.flags.FLAGS\n",
    "\n",
    "conf.embedded_word_size  = 150\n",
    "conf.word_vector_size    = 500\n",
    "conf.conv_size           = 3\n",
    "conf.conv_stride         = 1\n",
    "conf.conv_features       = 1\n",
    "conf.iterations          = 300\n",
    "conf.learning_rate       = 1e-3\n",
    "conf.weights_reg_scale   = 1e-6\n",
    "conf.activity_reg_scale  = 1e-6\n",
    "conf.embedding_reg_scale = 1e-6\n",
    "conf.save_path           = os.path.join(base_dir, \"./checkpoints/noon\")\n",
    "conf.log_path            = \"/tmp/tf-checkpoints/deepscite-noon\"\n",
    "conf.data_dir            = data_dir\n",
    "\n",
    "checkpoint_path = os.path.join(base_dir, \"checkpoints/noon/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conf.minibatch_size = 100\n",
    "tf.reset_default_graph()\n",
    "train.main(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's feed in a single paper (title, abstract) into DeepScite and see what it thinks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Inference step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to convert the text into the format needed by the model. Each word is mapped to the index of the vector in the word embedding matrix (i.e. it's index in the `vocab.txt` file.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](deep-scite-model-with-vectors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_list = utils.load_vocabulary(data_dir)\n",
    "vocab_dict = {}\n",
    "for k, w in enumerate(vocab_list):\n",
    "    vocab_dict[w] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_wordids_for(s):\n",
    "    r = [vocab_dict[w] for w in utils.to_words(s) if w in vocab_dict ]\n",
    "    if r == []:\n",
    "        raise Exception(\"Found no words at all!\")\n",
    "    return \" \".join(map(str, r))\n",
    "\n",
    "def words_to_html(words, activations, threshold=5):\n",
    "    good_words = []\n",
    "    bad_words  = []\n",
    "\n",
    "    elts = []\n",
    "\n",
    "    for k, w in enumerate(words):\n",
    "        activation = round(float(activations[k]), 2)\n",
    "\n",
    "        style = \"\"\n",
    "        if activation > threshold:\n",
    "            good_words.append(w)\n",
    "            style = \"color: blue !important;\"\n",
    "\n",
    "        if activation < -threshold:\n",
    "            bad_words.append(w)\n",
    "            style = \"color: red !important;\"\n",
    "\n",
    "        elts.append(\"<span style='{}' title='({},{})'>{}</span>\".format(\n",
    "                style,\n",
    "                activation,\n",
    "                round(float(activations[k]), 2), w))\n",
    "    \n",
    "    return \" \".join(elts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the model and emit a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def infer(title, abstract):\n",
    "    inputs = [ {\"id\": \"\", \n",
    "                \"wordset_1_ids\": get_wordids_for(title), \n",
    "                \"wordset_2_ids\": get_wordids_for(abstract) } ]\n",
    "\n",
    "    m = model.JointEmbeddingModelForBinaryClassification(conf.embedded_word_size)\n",
    "\n",
    "    # TensorFlow is uses a lot of global state. As a result, if we \n",
    "    # wish to re-run this cell many times, we need to have this\n",
    "    # statement here to ensure nothing is kept over.\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # We're only inputting one piece of data - a single paper.\n",
    "    conf.minibatch_size = 1\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        model_params = m.graph(\n",
    "            conf.minibatch_size,\n",
    "            len(vocab_list),\n",
    "            conf.word_vector_size,\n",
    "            conf.conv_size,\n",
    "            conf.conv_stride,\n",
    "            conf.conv_features\n",
    "        )\n",
    "\n",
    "        # Load the trained weights\n",
    "        saver = tf.train.Saver()\n",
    "        checkpoint = tf.train.latest_checkpoint(checkpoint_path)\n",
    "\n",
    "        if not checkpoint:\n",
    "            raise Exception(\"Couldn't find checkpoint at: {}\".format(checkpoint_path))\n",
    "\n",
    "        saver.restore(sess, checkpoint)\n",
    "\n",
    "        X1, X2, _, M1, M2, S1, S2, subset = train.get_datapoints(inputs)\n",
    "        data = {model_params.wordset_1: X1,\n",
    "                model_params.wordset_2: X2,\n",
    "                model_params.wordset_1_masks: M1,\n",
    "                model_params.wordset_2_masks: M2,\n",
    "                model_params.wordset_1_lengths: S1,\n",
    "                model_params.wordset_2_lengths: S2}\n",
    "\n",
    "\n",
    "        # Calculate the recommendations\n",
    "        set1_activations, set2_activations, final_probs, alpha = sess.run([\n",
    "            tf.squeeze(model_params.conv_wordset_1_activity, [2,3]),\n",
    "            tf.squeeze(model_params.conv_wordset_2_activity, [2,3]),\n",
    "            model_params.final_probs,\n",
    "            model_params.alpha], \n",
    "            feed_dict=data)\n",
    "    \n",
    "    return set1_activations[0], set2_activations[0], final_probs[0], alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## With what probability would Noon *scite* this paper?\n",
    "\n",
    "Enter candidate tiles and abstracts below. You can find inspiration over at [SciRate](https://scirate.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Very good\n",
    "title = r\"\"\"\n",
    "Architectures for quantum simulation showing quantum supremacy\n",
    "\"\"\"\n",
    "\n",
    "abstract = r\"\"\"\n",
    "One of the main aims in the field of quantum simulation is to achieve what is called \"quantum supremacy\", referring to the experimental realization of a quantum device that computationally outperforms classical computers. In this work, we show that one can devise versatile and feasible schemes of two-dimensional dynamical quantum simulators showing such a quantum supremacy, building on intermediate problems involving IQP circuits. In each of the schemes, an initial product state is prepared, potentially involving an element of randomness as in disordered models, followed by a short time evolution under a translationally invariant Hamiltonian with nearest-neighbor interactions and a mere sampling measurement in a fixed basis. The final state preparation in each scheme is fully efficiently certifiable. We discuss experimental necessities and possible physical architectures, inspired by platforms of cold atoms in optical lattices and a number of others, as well as specific assumptions that enter the complexity-theoretic arguments. This work shows that benchmark settings exhibiting a quantum advantage may require little control in contrast to universal quantum computing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "set1_activations, set2_activations, final_probs, alpha = infer(title, abstract)\n",
    "print(\"Scite Probability: {0:2.2f}%\".format(final_probs*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "nonzero   = [abs(x) for x in set1_activations if abs(x) > 0]\n",
    "threshold = np.mean(nonzero) / 2 \n",
    "\n",
    "title_words    = utils.to_words(title)\n",
    "abstract_words = utils.to_words(abstract)\n",
    "\n",
    "display(HTML(words_to_html(title_words,    set1_activations, threshold)))\n",
    "display(HTML(words_to_html(abstract_words, set2_activations, threshold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Weighting parameter\n",
    "\n",
    "$$\n",
    "    p = \\alpha * \\text{titles} + (1-\\alpha) * \\text{abstracts}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir /tmp/tf-checkpoints/deepscite-noon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
